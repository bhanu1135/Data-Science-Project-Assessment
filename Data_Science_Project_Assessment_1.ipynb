{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install docker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42s11IENNkGa",
        "outputId": "b2357950-7f69-43cf-baee-f724df216a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (7.1.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEe3WWJYQRBY",
        "outputId": "70a471a5-3d89-4048-9e27-d5cc4b571275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "import sqlite3\n",
        "import docker\n",
        "\n",
        "# 1. Data Scraping\n",
        "def scrape_article(url):\n",
        "    \"\"\"Retrieve the main text of a news article from the given URL.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        paragraphs = soup.find_all('p')\n",
        "        article_text = ' '.join([para.get_text() for para in paragraphs])\n",
        "        return article_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping the article: {e}\")\n",
        "        return None\n",
        "\n",
        "# 2. Entity Extraction\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_entities(text):\n",
        "    \"\"\"Extract PERSON and ORG entities from the given text.\"\"\"\n",
        "    doc = nlp(text)\n",
        "    entities = {'PERSON': [], 'ORG': []}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in entities:\n",
        "            entities[ent.label_].append(ent.text)\n",
        "    return entities\n",
        "\n",
        "# 3. Sentiment Analysis\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"Classify the sentiment of the text as positive, negative, or neutral.\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# 4. Database Storage\n",
        "def store_in_database(url, text, entities, sentiment):\n",
        "    \"\"\"Store the article details in a database.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect('articles.db')\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('''CREATE TABLE IF NOT EXISTS Articles (\n",
        "                            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                            url TEXT,\n",
        "                            content TEXT,\n",
        "                            entities TEXT,\n",
        "                            sentiment TEXT\n",
        "                          )''')\n",
        "        cursor.execute('''INSERT INTO Articles (url, content, entities, sentiment) VALUES (?, ?, ?, ?)''',\n",
        "                       (url, text, str(entities), sentiment))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error storing data: {e}\")\n",
        "\n",
        "# Fetching data\n",
        "def fetch_all_articles():\n",
        "    conn = sqlite3.connect('articles.db')\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM Articles\")\n",
        "    rows = cursor.fetchall()\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "    conn.close()\n",
        "\n",
        "# Clearing the Stored data\n",
        "def clear_database():\n",
        "    \"\"\"Clear all data from the database.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect('articles.db')\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('DELETE FROM Articles')  # Clears all data\n",
        "        cursor.execute('DELETE FROM sqlite_sequence WHERE name=\"Articles\"')  # Resets the auto-increment IDs\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        print(\"All data cleared from the database successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error clearing database: {e}\")\n",
        "\n",
        "# Main Functionality\n",
        "def main():\n",
        "    url = input(\"Enter the news article URL: \")\n",
        "    article_text = scrape_article(url)\n",
        "\n",
        "    if article_text:\n",
        "        print(\"\\nArticle scraped successfully.\")\n",
        "        entities = extract_entities(article_text)\n",
        "        print(\"Extracted Entities:\", entities)\n",
        "\n",
        "        sentiment = analyze_sentiment(article_text)\n",
        "        print(\"Sentiment:\", sentiment)\n",
        "\n",
        "        store_in_database(url, article_text, entities, sentiment)\n",
        "        print(\"Data stored in database successfully.\")\n",
        "\n",
        "      # fetch_all_articles() #it stores in the format---> id\turl\tcontent\tentities\tsentiment\n",
        "\n",
        "      # clear_database() #it clears the stored data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXW7vzLcN-Ao",
        "outputId": "577095f1-144c-4bc3-e593-58b164411632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the news article URL: https://www.themintmagazine.com/profit-and-profiteroles/\n",
            "\n",
            "Article scraped successfully.\n",
            "Extracted Entities: {'PERSON': ['Lebohang Liepollo Pheko', 'Covid', 'Gauteng', 'Zuma', 'Covid', 'Enoch Gondogwana', 'Lebohang'], 'ORG': ['The Mint Magazine', 'the African National Congress', 'ANC', 'ANC', 'ANC', 'ZAR 30bn', 'National Disaster Benefit Fund', 'Solidarity Fund', 'ZAR 500bn', 'the National Treasury Strategy', 'Kwa-Zulu', 'ANC', 'Social Relief of Distress', 'State', 'treasury', 'international trade & global financial governance', 'interviews & columns', 'PEP']}\n",
            "Sentiment: Positive\n",
            "Data stored in database successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YeCBCAy3RTTd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}